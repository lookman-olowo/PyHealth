{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRASP: Mortality Prediction on MIMIC-III\n",
    "\n",
    "This notebook demonstrates how to use the **GRASP** model for mortality prediction on the MIMIC-III dataset.\n",
    "\n",
    "**Paper**: Liantao Ma et al. \"GRASP: Generic Framework for Health Status Representation Learning Based on Incorporating Knowledge from Similar Patients.\" AAAI 2021.\n",
    "\n",
    "GRASP encodes patient sequences with a backbone (ConCare, GRU, or LSTM), clusters patients via k-means, refines cluster representations with a 2-layer GCN, and blends cluster-level knowledge back into individual patient representations via a learned gating mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the MIMIC-III Dataset\n",
    "\n",
    "We load the MIMIC-III dataset using PyHealth's `MIMIC3Dataset` class. We use the synthetic dataset hosted on GCS, which requires no credentials.\n",
    "\n",
    "- `root`: URL to the synthetic MIMIC-III data\n",
    "- `tables`: Clinical tables to load (diagnoses, procedures, prescriptions)\n",
    "- `dev`: Set to `True` for development/testing with a small subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "from pyhealth.datasets import MIMIC3Dataset\n",
    "\n",
    "base_dataset = MIMIC3Dataset(\n",
    "    root=\"https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III\",\n",
    "    tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\", \"PRESCRIPTIONS\"],\n",
    "    cache_dir=tempfile.TemporaryDirectory().name,\n",
    "    dev=True,\n",
    ")\n",
    "\n",
    "base_dataset.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the Mortality Prediction Task\n",
    "\n",
    "The `MortalityPredictionMIMIC3` task extracts samples from the raw EHR data:\n",
    "- Extracts diagnosis codes (ICD-9), procedure codes, and drug information from each visit\n",
    "- Creates binary labels based on in-hospital mortality\n",
    "- Filters out visits without sufficient clinical codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.tasks import MortalityPredictionMIMIC3\n",
    "\n",
    "task = MortalityPredictionMIMIC3()\n",
    "samples = base_dataset.set_task(task)\n",
    "\n",
    "print(f\"Generated {len(samples)} samples\")\n",
    "print(f\"\\nInput schema: {samples.input_schema}\")\n",
    "print(f\"Output schema: {samples.output_schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore a Sample\n",
    "\n",
    "Each sample represents one hospital visit with:\n",
    "- **conditions**: List of ICD-9 diagnosis codes\n",
    "- **procedures**: List of ICD-9 procedure codes\n",
    "- **drugs**: List of drug names\n",
    "- **mortality**: Binary label (0 = survived, 1 = deceased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample structure:\")\n",
    "print(samples[0])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "all_conditions = set()\n",
    "all_procedures = set()\n",
    "all_drugs = set()\n",
    "mortality_count = 0\n",
    "for sample in samples:\n",
    "    all_conditions.update(sample.get(\"conditions\", []))\n",
    "    all_procedures.update(sample.get(\"procedures\", []))\n",
    "    all_drugs.update(sample.get(\"drugs\", []))\n",
    "    mortality_count += float(sample.get(\"mortality\", 0))\n",
    "\n",
    "print(f\"Unique diagnosis codes: {len(all_conditions)}\")\n",
    "print(f\"Unique procedure codes: {len(all_procedures)}\")\n",
    "print(f\"Unique drugs: {len(all_drugs)}\")\n",
    "print(f\"\\nMortality rate: {mortality_count / len(samples) * 100:.2f}%\")\n",
    "print(f\"Positive samples: {int(mortality_count)}\")\n",
    "print(f\"Negative samples: {len(samples) - int(mortality_count)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split the Dataset\n",
    "\n",
    "We split the data by patient to avoid data leakage — all visits from a given patient go into the same split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import split_by_patient\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = split_by_patient(\n",
    "    samples, [0.8, 0.1, 0.1]\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Data Loaders\n",
    "\n",
    "Data loaders batch the samples and handle data feeding during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import get_dataloader\n",
    "\n",
    "train_dataloader = get_dataloader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = get_dataloader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = get_dataloader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training batches: {len(train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(val_dataloader)}\")\n",
    "print(f\"Test batches: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Initialize the GRASP Model\n",
    "\n",
    "The GRASP model automatically handles different feature types via `EmbeddingModel`.\n",
    "Sequence features (diagnosis/procedure/drug codes) are embedded using learned embeddings,\n",
    "and each feature gets its own `GRASPLayer`.\n",
    "\n",
    "### Key Parameters:\n",
    "- `embedding_dim`: Dimension of code embeddings (default: 128)\n",
    "- `hidden_dim`: Hidden dimension of the backbone (default: 128)\n",
    "- `cluster_num`: Number of patient clusters for knowledge sharing (default: 2)\n",
    "- `block`: Backbone encoder — `\"ConCare\"`, `\"GRU\"`, or `\"LSTM\"` (default: `\"ConCare\"`)\n",
    "- `dropout`: Dropout rate for regularization (default: 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pyhealth.models import GRASP\n\n# Note: cluster_num must be <= the smallest batch size in any dataloader.\n# With dev=True (~26 samples), use cluster_num=2 to avoid errors.\n# For full datasets (dev=False), cluster_num=10 or higher works well.\nmodel = GRASP(\n    dataset=samples,\n    embedding_dim=128,\n    hidden_dim=128,\n    cluster_num=2,\n)\n\nprint(f\"Model initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\nprint(f\"\\nModel architecture:\")\nprint(model)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train the Model\n",
    "\n",
    "We use PyHealth's `Trainer` class which handles:\n",
    "- Training loop with automatic batching\n",
    "- Validation during training\n",
    "- Model checkpointing based on validation metrics\n",
    "\n",
    "We monitor the **ROC-AUC** score on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    metrics=[\"roc_auc\", \"pr_auc\", \"accuracy\", \"f1\"],\n",
    ")\n",
    "\n",
    "trainer.train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    epochs=50,\n",
    "    monitor=\"roc_auc\",\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate on Test Set\n",
    "\n",
    "After training, we evaluate the model on the held-out test set to measure its generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate(test_dataloader)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Test Set Performance\")\n",
    "print(\"=\" * 50)\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Extract Patient Embeddings\n",
    "\n",
    "GRASP produces patient embeddings that encode health status enriched with knowledge from similar patients.\n",
    "These embeddings can be used for downstream tasks like patient similarity search, cohort discovery, or transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()\n",
    "test_batch = next(iter(test_dataloader))\n",
    "test_batch[\"embed\"] = True\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(**test_batch)\n",
    "\n",
    "print(f\"Embedding shape: {output['embed'].shape}\")\n",
    "print(f\"  - Batch size: {output['embed'].shape[0]}\")\n",
    "print(f\"  - Embedding dim: {output['embed'].shape[1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\" * 50)\n",
    "predictions = output[\"y_prob\"].cpu().numpy()\n",
    "true_labels = output[\"y_true\"].cpu().numpy()\n",
    "\n",
    "for i in range(min(5, len(predictions))):\n",
    "    pred = predictions[i][0]\n",
    "    true = int(true_labels[i][0])\n",
    "    print(f\"Patient {i + 1}: Predicted={pred:.3f}, True={true}, Prediction={'Mortality' if pred > 0.5 else 'Survival'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}